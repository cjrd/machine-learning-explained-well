# Machine Learning Explained Well
I am a former machine learning researcher who took a break from academia for ~5 years to build a startup. Now I've returned to research, and I'm often hunting for really good explanations of machine learning ideas (it's rare that they come from the original research paper). When I find an exceptional explanation/tutorial/etc, I'll add it here. 

* Attention/Transformers
    * [Post from Peter Bloem](http://www.peterbloem.nl/blog/transformers)
* Capsule Networks 
    * [Tutorial video from
Aurélien Géron](https://www.youtube.com/watch?v=pPN8d0E3900)
    * [Tutorial sequence from Max Pechyonkin](https://pechyonkin.me/capsules-1/)
* Conditional Random Fields 
    * [Overview & general feel (start here)](https://medium.com/ml2vec/overview-of-conditional-random-fields-68a2a20fa541)
* GANs
    * [WGAN and WGAN-GP tutorial](https://medium.com/@jonathan_hui/gan-wasserstein-gan-wgan-gp-6a1a2aa1b490)
* Network Dissection
    * [7.1.2 Network Dissection](https://christophm.github.io/interpretable-ml-book/cnn-features.html#feature-visualization)
* Normalizing Flows
    * [Sculpting Distributions with Normalizing Flows](https://www.ritchievink.com/blog/2019/10/11/sculpting-distributions-with-normalizing-flows/)
* R-CNN & Common Variants
    * [tutorial](https://towardsdatascience.com/deep-learning-for-object-detection-a-comprehensive-review-73930816d8d9)
* Resnet
    * [tutorial](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035)
    
    
